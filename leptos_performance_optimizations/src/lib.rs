//! Leptos Performance Optimizations
//!
//! High-performance implementations addressing bottlenecks identified
//! in the reactive system analysis.

use smallvec::SmallVec;
use std::sync::{Arc, RwLock};
use std::cell::RefCell;

/// Optimized subscriber storage for signals
/// Uses inline storage for common case of â‰¤3 subscribers (90% of signals)
#[derive(Debug)]
pub enum SubscriberStorage {
    /// Inline storage for up to 3 subscribers (most common)
    Inline {
        subscribers: [Option<AnySubscriber>; 3],
        count: u8,
    },
    /// Heap storage for signals with many subscribers
    Heap(Vec<AnySubscriber>),
}

impl SubscriberStorage {
    pub fn new() -> Self {
        Self::Inline {
            subscribers: [None, None, None],
            count: 0,
        }
    }

    pub fn add_subscriber(&mut self, subscriber: AnySubscriber) {
        match self {
            Self::Inline { subscribers, count } => {
                if *count < 3 {
                    subscribers[*count as usize] = Some(subscriber);
                    *count += 1;
                } else {
                    // Convert to heap storage
                    let mut heap_subs = Vec::with_capacity(4);
                    for sub in subscribers.iter_mut() {
                        if let Some(s) = sub.take() {
                            heap_subs.push(s);
                        }
                    }
                    heap_subs.push(subscriber);
                    *self = Self::Heap(heap_subs);
                }
            }
            Self::Heap(subs) => {
                subs.push(subscriber);
            }
        }
    }

    pub fn remove_subscriber(&mut self, id: SubscriberId) -> bool {
        match self {
            Self::Inline { subscribers, count } => {
                for (i, slot) in subscribers.iter_mut().enumerate() {
                    if let Some(sub) = slot {
                        if sub.id() == id {
                            *slot = None;
                            if *count > 0 {
                                *count -= 1;
                            }
                            // Compact the array
                            for j in i..*count as usize {
                                subscribers[j] = subscribers[j + 1].take();
                            }
                            return true;
                        }
                    }
                }
                false
            }
            Self::Heap(subs) => {
                if let Some(pos) = subs.iter().position(|s| s.id() == id) {
                    subs.remove(pos);
                    // Convert back to inline if small enough
                    if subs.len() <= 3 {
                        let mut inline = [None, None, None];
                        let drain_count = subs.len();
                        for (i, sub) in subs.drain(..).enumerate() {
                            inline[i] = Some(sub);
                        }
                        *self = Self::Inline {
                            subscribers: inline,
                            count: drain_count as u8,
                        };
                    }
                    true
                } else {
                    false
                }
            }
        }
    }

    pub fn notify_subscribers(&self) {
        match self {
            Self::Inline { subscribers, count } => {
                for i in 0..*count as usize {
                    if let Some(sub) = &subscribers[i] {
                        sub.mark_dirty();
                    }
                }
            }
            Self::Heap(subs) => {
                for sub in subs {
                    sub.mark_dirty();
                }
            }
        }
    }

    pub fn len(&self) -> usize {
        match self {
            Self::Inline { count, .. } => *count as usize,
            Self::Heap(subs) => subs.len(),
        }
    }
}

/// Batched update system for reducing DOM operations
pub struct UpdateBatch {
    signals_to_update: SmallVec<[AnySignal; 8]>,
    effects_to_run: SmallVec<[AnyEffect; 16]>,
    dom_updates: SmallVec<[DomUpdate; 32]>,
    is_batching: bool,
}

impl UpdateBatch {
    thread_local! {
        static CURRENT_BATCH: RefCell<UpdateBatch> = RefCell::new(UpdateBatch::new());
    }

    fn new() -> Self {
        Self {
            signals_to_update: SmallVec::new(),
            effects_to_run: SmallVec::new(),
            dom_updates: SmallVec::new(),
            is_batching: false,
        }
    }

    /// Execute updates in batch to minimize DOM operations
    pub fn batch_updates<F, R>(f: F) -> R
    where
        F: FnOnce() -> R,
    {
        Self::CURRENT_BATCH.with(|batch| {
            let was_batching = batch.borrow().is_batching;
            
            if was_batching {
                // Already batching, just run the function
                return f();
            }

            // Start batching
            batch.borrow_mut().is_batching = true;
            
            let result = f();
            
            // Commit batch
            let mut batch = batch.borrow_mut();
            batch.commit();
            batch.is_batching = false;
            
            result
        })
    }

    fn add_signal_update(&mut self, signal: AnySignal) {
        if !self.signals_to_update.contains(&signal) {
            self.signals_to_update.push(signal);
        }
    }

    fn add_effect(&mut self, effect: AnyEffect) {
        if !self.effects_to_run.contains(&effect) {
            self.effects_to_run.push(effect);
        }
    }

    fn commit(&mut self) {
        // 1. Update all signals
        for signal in self.signals_to_update.drain(..) {
            signal.flush_update();
        }

        // 2. Run effects in priority order
        self.effects_to_run.sort_by_key(|e| e.priority());
        for effect in self.effects_to_run.drain(..) {
            effect.run();
        }

        // 3. Apply DOM updates in batch
        if !self.dom_updates.is_empty() {
            self.apply_dom_updates();
        }
    }

    fn apply_dom_updates(&mut self) {
        // Group DOM updates by type for efficiency
        let mut text_updates = Vec::new();
        let mut attribute_updates = Vec::new();
        let mut style_updates = Vec::new();

        for update in self.dom_updates.drain(..) {
            match update {
                DomUpdate::Text { .. } => text_updates.push(update),
                DomUpdate::Attribute { .. } => attribute_updates.push(update),
                DomUpdate::Style { .. } => style_updates.push(update),
            }
        }

        // Apply updates in batches to minimize layout thrashing
        for update in text_updates {
            update.apply();
        }
        for update in attribute_updates {
            update.apply();
        }
        for update in style_updates {
            update.apply();
        }
    }
}

/// Effect scheduling with priority levels
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum EffectPriority {
    Immediate = 0, // DOM updates, user interactions
    Normal = 1,    // Business logic
    Low = 2,       // Analytics, logging
}

pub struct EffectScheduler {
    queues: [Vec<AnyEffect>; 3],
    is_flushing: bool,
}

impl EffectScheduler {
    thread_local! {
        static SCHEDULER: RefCell<EffectScheduler> = RefCell::new(EffectScheduler::new());
    }

    fn new() -> Self {
        Self {
            queues: [Vec::new(), Vec::new(), Vec::new()],
            is_flushing: false,
        }
    }

    pub fn schedule(effect: AnyEffect, priority: EffectPriority) {
        Self::SCHEDULER.with(|scheduler| {
            let mut s = scheduler.borrow_mut();
            s.queues[priority as usize].push(effect);
            
            if !s.is_flushing {
                s.flush();
            }
        });
    }

    fn flush(&mut self) {
        self.is_flushing = true;

        // Process queues in priority order
        for queue in &mut self.queues {
            while let Some(effect) = queue.pop() {
                effect.run();
            }
        }

        self.is_flushing = false;
    }
}

/// Optimized signal implementation addressing performance bottlenecks
pub struct OptimizedSignal<T> {
    inner: Arc<RwLock<SignalInner<T>>>,
    id: SignalId,
}

struct SignalInner<T> {
    value: T,
    subscribers: SubscriberStorage,
    generation: u64, // For optimistic reads
    dirty: bool,
}

impl<T: Clone + 'static> OptimizedSignal<T> {
    pub fn new(value: T) -> Self {
        Self {
            inner: Arc::new(RwLock::new(SignalInner {
                value,
                subscribers: SubscriberStorage::new(),
                generation: 0,
                dirty: false,
            })),
            id: SignalId::new(),
        }
    }

    /// Optimistic read without write lock
    pub fn get(&self) -> T {
        // Fast path: try optimistic read
        if let Ok(inner) = self.inner.try_read() {
            if !inner.dirty {
                return inner.value.clone();
            }
        }

        // Slow path: acquire read lock
        let inner = self.inner.read().unwrap();
        inner.value.clone()
    }

    /// Batch-aware update
    pub fn set(&self, new_value: T) {
        UpdateBatch::CURRENT_BATCH.with(|batch| {
            if batch.borrow().is_batching {
                // Just mark as dirty and queue for later
                self.mark_dirty_and_queue(new_value);
            } else {
                // Update immediately
                self.update_immediately(new_value);
            }
        });
    }

    fn mark_dirty_and_queue(&self, new_value: T) {
        let mut inner = self.inner.write().unwrap();
        inner.value = new_value;
        inner.dirty = true;
        inner.generation += 1;

        UpdateBatch::CURRENT_BATCH.with(|batch| {
            batch.borrow_mut().add_signal_update(AnySignal { id: self.id });
        });
    }

    fn update_immediately(&self, new_value: T) {
        let mut inner = self.inner.write().unwrap();
        inner.value = new_value;
        inner.generation += 1;
        inner.dirty = false;
        
        // Notify subscribers inline to avoid cloning
        inner.subscribers.notify_subscribers();
    }

    pub fn flush_update(&self) {
        let mut inner = self.inner.write().unwrap();
        if inner.dirty {
            inner.dirty = false;
            inner.subscribers.notify_subscribers();
        }
    }
}

/// Visitor pattern for subscribers to avoid cloning
pub trait SubscriberVisitor {
    fn visit(&mut self, subscriber: &AnySubscriber);
}

impl SubscriberStorage {
    pub fn visit_subscribers<V: SubscriberVisitor>(&self, mut visitor: V) {
        match self {
            Self::Inline { subscribers, count } => {
                for i in 0..*count as usize {
                    if let Some(sub) = &subscribers[i] {
                        visitor.visit(sub);
                    }
                }
            }
            Self::Heap(subs) => {
                for sub in subs {
                    visitor.visit(sub);
                }
            }
        }
    }
}

/// Memory pool for commonly allocated objects
pub struct MemoryPool<T> {
    pool: RefCell<Vec<T>>,
    create_fn: fn() -> T,
}

impl<T> MemoryPool<T> {
    pub fn new(create_fn: fn() -> T) -> Self {
        Self {
            pool: RefCell::new(Vec::new()),
            create_fn,
        }
    }

    pub fn get(&self) -> T {
        self.pool.borrow_mut().pop().unwrap_or_else(self.create_fn)
    }

    pub fn return_to_pool(&self, item: T) {
        let mut pool = self.pool.borrow_mut();
        if pool.len() < 100 {  // Prevent unbounded growth
            pool.push(item);
        }
    }
}

// Placeholder types that would be properly defined in the actual implementation
#[derive(Debug, Clone, PartialEq)]
pub struct AnySubscriber {
    pub id: SubscriberId,
}

impl AnySubscriber {
    pub fn id(&self) -> SubscriberId {
        self.id
    }

    pub fn mark_dirty(&self) {
        // Implementation would mark the subscriber as needing update
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub struct SubscriberId(pub u64);

#[derive(Debug, Clone, PartialEq)]
pub struct AnySignal {
    id: SignalId,
}

impl AnySignal {
    pub fn flush_update(&self) {
        // Implementation would flush pending updates
    }
}

impl<T> From<OptimizedSignal<T>> for AnySignal {
    fn from(signal: OptimizedSignal<T>) -> Self {
        AnySignal { id: signal.id }
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub struct SignalId(u64);

impl SignalId {
    fn new() -> Self {
        use std::sync::atomic::{AtomicU64, Ordering};
        static NEXT_ID: AtomicU64 = AtomicU64::new(1);
        Self(NEXT_ID.fetch_add(1, Ordering::Relaxed))
    }
}

#[derive(Debug, Clone, PartialEq)]
pub struct AnyEffect {
    priority: EffectPriority,
}

impl AnyEffect {
    pub fn priority(&self) -> EffectPriority {
        self.priority
    }

    pub fn run(&self) {
        // Implementation would run the effect
    }
}

#[derive(Debug, Clone)]
pub enum DomUpdate {
    Text { element_id: u64, text: String },
    Attribute { element_id: u64, name: String, value: String },
    Style { element_id: u64, property: String, value: String },
}

impl DomUpdate {
    pub fn apply(&self) {
        // Implementation would apply the DOM update
        match self {
            Self::Text { .. } => {
                // Update text content
            }
            Self::Attribute { .. } => {
                // Set attribute
            }
            Self::Style { .. } => {
                // Update style property
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_subscriber_storage_inline() {
        let mut storage = SubscriberStorage::new();
        assert_eq!(storage.len(), 0);

        // Add subscribers to inline storage
        for i in 0..3 {
            storage.add_subscriber(AnySubscriber {
                id: SubscriberId(i),
            });
        }
        assert_eq!(storage.len(), 3);

        // Should still be inline
        if let SubscriberStorage::Inline { .. } = storage {
            // Good
        } else {
            panic!("Should still be inline storage");
        }
    }

    #[test]
    fn test_subscriber_storage_converts_to_heap() {
        let mut storage = SubscriberStorage::new();

        // Add 4 subscribers - should convert to heap
        for i in 0..4 {
            storage.add_subscriber(AnySubscriber {
                id: SubscriberId(i),
            });
        }

        assert_eq!(storage.len(), 4);
        if let SubscriberStorage::Heap(..) = storage {
            // Good
        } else {
            panic!("Should have converted to heap storage");
        }
    }

    #[test]
    fn test_batched_updates() {
        let signal = OptimizedSignal::new(0i32);
        let mut updates_count = 0;

        let result = UpdateBatch::batch_updates(|| {
            signal.set(1);
            signal.set(2);
            signal.set(3);
            "result"
        });

        assert_eq!(result, "result");
        // In a real implementation, we'd verify that only one update was applied
    }

    #[test]
    fn test_effect_priority_ordering() {
        // Test that effects are scheduled in priority order
        let effect_low = AnyEffect { priority: EffectPriority::Low };
        let effect_immediate = AnyEffect { priority: EffectPriority::Immediate };
        let effect_normal = AnyEffect { priority: EffectPriority::Normal };

        // Priority ordering should be: Immediate < Normal < Low
        assert!(effect_immediate.priority() < effect_normal.priority());
        assert!(effect_normal.priority() < effect_low.priority());
    }

    #[test]
    fn test_memory_pool() {
        let pool = MemoryPool::new(|| String::from("default"));
        
        // First get should create new
        let item1 = pool.get();
        assert_eq!(item1, "default");
        
        // Return to pool
        pool.return_to_pool(String::from("reused"));
        
        // Next get should reuse
        let item2 = pool.get();
        assert_eq!(item2, "reused");
    }
}